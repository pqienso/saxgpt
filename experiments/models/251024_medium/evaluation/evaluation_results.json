{
  "test_loss": 4.404374920803567,
  "test_accuracy": 0.18520954348470853,
  "test_perplexity": 89.30839870287025,
  "codebook_0_loss": 3.6828589594882466,
  "codebook_0_accuracy": 0.23934540930001633,
  "codebook_1_loss": 4.332391821819803,
  "codebook_1_accuracy": 0.18714975760034894,
  "codebook_2_loss": 4.641153428865516,
  "codebook_2_accuracy": 0.17212077262608902,
  "codebook_3_loss": 4.9610954471256425,
  "codebook_3_accuracy": 0.14222222080697183,
  "gen_accuracy_temp_0.8": 0.09707846492528915,
  "gen_seq_accuracy_temp_0.8": 0.0,
  "gen_accuracy_temp_1.0": 0.05613522604107857,
  "gen_seq_accuracy_temp_1.0": 0.0,
  "gen_accuracy_temp_1.2": 0.06110183522105217,
  "gen_seq_accuracy_temp_1.2": 0.0,
  "autoregressive_consistency": 0.4135638177394867,
  "first_divergence_position": 5,
  "num_unique_predicted": 1983,
  "num_unique_target": 1979,
  "predicted_entropy": 6.703552883971316,
  "target_entropy": 6.886955266347265,
  "fad_score": 4.781231337916456,
  "fad_model": "vggish",
  "fad_num_samples": 50,
  "timestamp": "2025-11-16T12:30:16.830042",
  "model_config": {
    "vocab_size": 2049,
    "num_codebooks": 4,
    "d_model": 384,
    "nhead": 6,
    "num_encoder_layers": 6,
    "num_decoder_layers": 6,
    "dim_feedforward": 1536,
    "dropout": 0.1,
    "activation": "relu",
    "norm_first": true,
    "max_seq_len": 1505,
    "padding_idx": 2048,
    "scale_embeddings": true
  }
}