{
  "test_loss": 4.404375698255456,
  "test_accuracy": 0.18521135494760846,
  "test_perplexity": 89.30847226018491,
  "codebook_0_loss": 3.6828598095023115,
  "codebook_0_accuracy": 0.23934540930001633,
  "codebook_1_loss": 4.332392526709515,
  "codebook_1_accuracy": 0.18714975760034894,
  "codebook_2_loss": 4.64115425814753,
  "codebook_2_accuracy": 0.17212801912556525,
  "codebook_3_loss": 4.961096058721128,
  "codebook_3_accuracy": 0.14222222080697183,
  "gen_accuracy_temp_0.8": 0.0963689461350441,
  "gen_seq_accuracy_temp_0.8": 0.0,
  "gen_accuracy_temp_1.0": 0.035350583493709564,
  "gen_seq_accuracy_temp_1.0": 0.0,
  "gen_accuracy_temp_1.2": 0.01911519281566143,
  "gen_seq_accuracy_temp_1.2": 0.0,
  "autoregressive_consistency": 0.4135638177394867,
  "first_divergence_position": 5,
  "num_unique_predicted": 1983,
  "num_unique_target": 1979,
  "predicted_entropy": 6.703549859902989,
  "target_entropy": 6.886955266347265,
  "kl_divergence_token_dist": 0.0722971964534233,
  "kl_divergence_avg": 4.404539585113525,
  "fad_score": 4.932607567809686,
  "fad_model": "vggish",
  "fad_num_samples": 50,
  "timestamp": "2025-11-16T13:30:43.285714",
  "model_config": {
    "vocab_size": 2049,
    "num_codebooks": 4,
    "d_model": 384,
    "nhead": 6,
    "num_encoder_layers": 6,
    "num_decoder_layers": 6,
    "dim_feedforward": 1536,
    "dropout": 0.1,
    "activation": "relu",
    "norm_first": true,
    "max_seq_len": 1505,
    "padding_idx": 2048,
    "scale_embeddings": true
  }
}