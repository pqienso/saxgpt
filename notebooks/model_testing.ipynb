{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "711b0402-2c7d-4ffe-adc6-2dc51ee7b860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from ../../../Downloads/kaggle_output/model/checkpoints/latest.pt\n",
      "Checkpoint info:\n",
      "  Epoch: 390\n",
      "  Step: 228344\n",
      "  Metrics: {'train_loss': 2.6828079223632812, 'train_accuracy': 0.3786788582801819, 'val_loss': 4.793875694274902, 'val_accuracy': 0.21112987399101257}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.training.util.checkpointing import load_checkpoint_for_inference\n",
    "from src.training.util.config_model import load_config, create_model\n",
    "from src.data.util.tokenization import detokenize\n",
    "from src.data.util.codes_interleaving import remove_delay_interleaving\n",
    "import torch\n",
    "import torchaudio\n",
    "from typing import Tuple\n",
    "from pathlib import Path\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "config = load_config(\"../config/model/large.yaml\")\n",
    "model = create_model(config).to(device)\n",
    "model.eval()\n",
    "load_checkpoint_for_inference(model, \"../../../Downloads/kaggle_output/model/checkpoints/latest.pt\", device)\n",
    "\n",
    "test_ds = torch.load(\"../data/main/7_datasets/test.pt\", weights_only=False)\n",
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75ccfa9a-ed32-44c5-9386-b9f7b875decf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num entries correct: 97 / 6010\n",
      "tensor([[[2048,  798,  932,  ...,   83,   83,   83],\n",
      "         [2048, 2048, 1931,  ..., 1931, 1931, 1931],\n",
      "         [2048, 2048, 2048,  ..., 2019, 2019, 2019],\n",
      "         [2048, 2048, 2048,  ..., 1854, 1770, 1770]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_NUMBER = 27\n",
    "\n",
    "def get_generated_audio(\n",
    "    model: torch.nn.Module,\n",
    "    example: Tuple[torch.Tensor, torch.Tensor],\n",
    "    save_dir: str = \"./outputs/\",\n",
    "    greedy: bool = True,\n",
    "    teacher_forcing: bool = False,\n",
    "    **sampling_args,\n",
    "):\n",
    "    src, tgt = example\n",
    "    src = src.to(device).unsqueeze(0)\n",
    "    tgt = tgt.to(device)\n",
    "    save_dir = Path(save_dir)\n",
    "    start_tokens = torch.tensor(\n",
    "        [[2048 for _ in range(4)]],\n",
    "        dtype=torch.int,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    if teacher_forcing:\n",
    "        out = model(src, tgt[:, :-1].unsqueeze(0)).argmax(dim=-1, keepdim=False)\n",
    "        out = torch.cat(\n",
    "            [torch.tensor([[[2048] for _ in range(4)]]), out],\n",
    "            dim=-1\n",
    "        )\n",
    "    elif greedy:\n",
    "        out = model.generate_greedy(\n",
    "            src,\n",
    "            max_len=1505,\n",
    "            start_tokens=start_tokens,\n",
    "        )\n",
    "    else:\n",
    "        out = model.generate(\n",
    "            src,\n",
    "            max_len=1505,\n",
    "            start_tokens=start_tokens,\n",
    "            **sampling_args,\n",
    "        )\n",
    "    num_nums = 1\n",
    "    for i in out.shape:\n",
    "        num_nums *= i\n",
    "    print(f\"num entries correct: {(out[0] == tgt).sum().item()} / {num_nums - 10}\")\n",
    "    print(out)\n",
    "    tokens = out\n",
    "    src = detokenize(remove_delay_interleaving(src[0].cpu()))\n",
    "    out = detokenize(remove_delay_interleaving(out[0].cpu()))\n",
    "    tgt = detokenize(remove_delay_interleaving(tgt.cpu()))\n",
    "    \n",
    "    torchaudio.save(save_dir / \"tgt_model.wav\", out, 32000)\n",
    "    torchaudio.save(save_dir / \"src.wav\", src, 32000)\n",
    "    torchaudio.save(save_dir / \"tgt_ground_truth.wav\", tgt, 32000)\n",
    "\n",
    "    torchaudio.save(\n",
    "        save_dir / \"combined_model.wav\",\n",
    "        torch.clip(out + src, -1.0, 1.0),\n",
    "        32000,\n",
    "    )\n",
    "    torchaudio.save(\n",
    "        save_dir / \"combined_ground_truth.wav\",\n",
    "        torch.clip(tgt + src, -1.0, 1.0), \n",
    "        32000,\n",
    "    )\n",
    "    return tokens\n",
    "    \n",
    "out = get_generated_audio(model, test_ds[SAMPLE_NUMBER], greedy=False, temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "08cfc08c-53a7-4ea6-9c63-5c7f946c0128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2048,   83,   83,   83,   83,   83,   83,   83,   83,   83,   83,\n",
       "            83,   83,   83,   83,   83,   83,   83,   83,   83,   83,   83,\n",
       "            83,   83,   83,   83,   83,   83,   83,   83,   83,   83,   83,\n",
       "            83,   83,   83,   83,   83,   83,   83,   83,   83,   83,  778,\n",
       "           237, 1600, 1126,  457,  457,  457,  457, 1221,  457,  457, 1103,\n",
       "          1103, 1103, 1111, 1111, 1111,  960, 1257, 1103, 1744, 1744, 1744,\n",
       "           903, 1744, 1103, 1544, 1544, 1639,  361,  813, 1111,  879,  311,\n",
       "           624,  311,  624, 1103, 1231, 1472, 1201,  457,  624, 1201, 1701,\n",
       "           311, 1697, 1201, 1103,  879, 1103, 1103, 1103, 1103, 1103, 1103,\n",
       "          1103],\n",
       "         [2048, 2048, 1931, 1931, 1931, 1931, 1931, 2044, 2044, 1931, 2044,\n",
       "          2044, 2044, 2044, 2044, 1931, 2044, 2044, 2044, 2044, 2044, 2044,\n",
       "          2044, 2044, 2044, 2044, 2044, 2044, 2044, 2044, 2044, 2044, 2044,\n",
       "          2044, 1931, 2044, 1931, 2044, 2044, 2044, 2044, 1489, 2044, 2044,\n",
       "          2044, 1450,  851, 1353, 1450, 1837, 1861, 1450,  237,  170, 1178,\n",
       "          1861, 1974, 1224,  237, 1255, 1078,  139, 1255, 1919, 1919,  563,\n",
       "           330, 1623,  101, 1137,  330,  101, 1454, 1267, 1200,  101, 1454,\n",
       "          1331,  740, 1178,  237, 1649,  740,  867,  740,  901,  161, 1542,\n",
       "          1202,  901,  621, 1804, 1572,  161, 1815, 1461, 1450,  481, 1623,\n",
       "           975],\n",
       "         [2048, 2048, 2048, 2019, 2019, 2019, 2019, 2019, 2019, 1912, 1912,\n",
       "          1912, 1912, 1912, 1912, 1912, 1912, 1912, 1912, 1912, 1912, 1912,\n",
       "          1912, 1912, 1912, 1912, 1912, 1912, 1912, 1912, 1912, 1912, 2019,\n",
       "          2019, 1912, 1912, 1912, 1912, 1912, 1912, 1912, 1912, 2019, 1912,\n",
       "          1912, 2015, 2000,  342,  950,  807, 1854, 1821,  466, 1582,  600,\n",
       "          1434, 1854, 1523, 1699, 1474,  670,  600,  628,  600, 1546, 1392,\n",
       "           127, 1817, 1173, 1055, 1705, 1745, 1385,  670, 1946, 1519, 1519,\n",
       "          1570,    9, 1364,  308, 1084, 1415, 1620,  604,  446, 1335, 1335,\n",
       "           604,  752, 1525, 1800, 1204,  629,  342, 1407, 1568, 1352,  722,\n",
       "          1727],\n",
       "         [2048, 2048, 2048, 2048, 1770, 1770, 1770, 1770, 1770, 1676, 1770,\n",
       "          1770, 1670, 1670, 1670, 1670, 1670, 1670, 1670, 1670, 1670, 1670,\n",
       "          1670, 1670, 1670, 1670, 1670, 1670, 1670, 1670, 1670, 1903, 1670,\n",
       "           346,  433, 1770, 1670, 1670, 1670, 1670, 1670, 1670, 1770, 1903,\n",
       "          1903, 1903, 1770,  361, 1625,   68,  401,  239, 1803, 1184, 1780,\n",
       "           647,  394,  394,   68,   55, 1803,  912,  341, 1842,  341, 1842,\n",
       "           870, 1884,  912, 2040, 1884,  654, 1884,  654,  652,  583, 1572,\n",
       "           456, 1919, 1878,  841, 1212,  456,  249, 2025, 1240,  126, 1088,\n",
       "          1336, 1334, 1726, 1219, 1219,  129, 1212,  280,   53, 1212,  753,\n",
       "            43]]], device='cuda:0')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:, :, :100]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
