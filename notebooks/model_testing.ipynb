{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "711b0402-2c7d-4ffe-adc6-2dc51ee7b860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from ../../../Downloads/model/checkpoints/latest.pt\n",
      "Checkpoint info:\n",
      "  Epoch: 248\n",
      "  Step: 31125\n",
      "  Metrics: {'train_loss': 2.151264190673828, 'train_accuracy': 0.4707900881767273, 'val_loss': 6.298453330993652, 'val_accuracy': 0.11502083390951157}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18688"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.training.util.training import load_checkpoint_for_inference, load_config, create_model\n",
    "from src.data.util.tokenization import detokenize\n",
    "from src.data.util.codes_interleaving import remove_delay_interleaving\n",
    "import torch\n",
    "import torchaudio\n",
    "from typing import Tuple\n",
    "from pathlib import Path\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "config = load_config(\"../config/model/medium.yaml\")\n",
    "model = create_model(config).to(device)\n",
    "model.eval()\n",
    "load_checkpoint_for_inference(model, \"../../../Downloads/model/checkpoints/latest.pt\", device)\n",
    "\n",
    "test_ds = torch.load(\"../data/main/7_datasets/train.pt\", weights_only=False)\n",
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75ccfa9a-ed32-44c5-9386-b9f7b875decf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num entries correct: 301 / 6010\n",
      "tensor([[[2048, 1667, 1667,  ...,   83,   83,   83],\n",
      "         [2048, 2048, 1758,  ...,  938, 1955, 1497],\n",
      "         [2048, 2048, 2048,  ...,  924, 1938, 1938],\n",
      "         [2048, 2048, 2048,  ..., 1595, 1854, 2040]]])\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_NUMBER = 100\n",
    "\n",
    "def get_generated_audio(\n",
    "    model: torch.nn.Module,\n",
    "    example: Tuple[torch.Tensor, torch.Tensor],\n",
    "    save_dir: str = \"./outputs/\",\n",
    "    greedy: bool = True,\n",
    "    teacher_forcing: bool = False,\n",
    "    **sampling_args,\n",
    "):\n",
    "    src, tgt = example\n",
    "    src = src.to(device).unsqueeze(0)\n",
    "    tgt = tgt.to(device)\n",
    "    save_dir = Path(save_dir)\n",
    "    start_tokens = torch.tensor(\n",
    "        [[2048 for _ in range(4)]],\n",
    "        dtype=torch.int,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    if teacher_forcing:\n",
    "        out = model(src, tgt[:, :-1].unsqueeze(0)).argmax(dim=-1, keepdim=False)\n",
    "        out = torch.cat(\n",
    "            [torch.tensor([[[2048] for _ in range(4)]]), out],\n",
    "            dim=-1\n",
    "        )\n",
    "    elif greedy:\n",
    "        out = model.generate_greedy(\n",
    "            src,\n",
    "            max_len=1505,\n",
    "            start_tokens=start_tokens,\n",
    "        )\n",
    "    else:\n",
    "        out = model.generate(\n",
    "            src,\n",
    "            max_len=1505,\n",
    "            start_tokens=start_tokens,\n",
    "            **sampling_args,\n",
    "        )\n",
    "    num_nums = 1\n",
    "    for i in out.shape:\n",
    "        num_nums *= i\n",
    "    print(f\"num entries correct: {(out[0] == tgt).sum().item()} / {num_nums - 10}\")\n",
    "    print(out)\n",
    "    tokens = out\n",
    "    src = detokenize(remove_delay_interleaving(src[0]))\n",
    "    out = detokenize(remove_delay_interleaving(out[0]))\n",
    "    tgt = detokenize(remove_delay_interleaving(tgt))\n",
    "    \n",
    "    torchaudio.save(save_dir / \"tgt_model.wav\", out, 32000)\n",
    "    torchaudio.save(save_dir / \"src.wav\", src, 32000)\n",
    "    torchaudio.save(save_dir / \"tgt_ground_truth.wav\", tgt, 32000)\n",
    "\n",
    "    torchaudio.save(\n",
    "        save_dir / \"combined_model.wav\",\n",
    "        torch.clip(out + src, -1.0, 1.0),\n",
    "        32000,\n",
    "    )\n",
    "    torchaudio.save(\n",
    "        save_dir / \"combined_ground_truth.wav\",\n",
    "        torch.clip(tgt + src, -1.0, 1.0), \n",
    "        32000,\n",
    "    )\n",
    "    return tokens\n",
    "    \n",
    "out = get_generated_audio(model, test_ds[SAMPLE_NUMBER], greedy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "08cfc08c-53a7-4ea6-9c63-5c7f946c0128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2048, 1667, 1667, 1318,  793,   66,   83, 1131,  248,   50,  457,\n",
       "          1913, 1364,  932,  840,  865, 1627,  685, 2036, 2031,  494, 1479,\n",
       "           520, 1667,  965, 1702,  520,  494,   66,   83,   83,  166,  166,\n",
       "           166,  166,  166,  166,   83,  965, 1388, 2036,  954, 1667,  443,\n",
       "            83, 1757,    8, 1373, 1044, 1389, 1479,  237, 1506,  974, 1648,\n",
       "           573, 1814, 1685,  629, 2016, 1685, 1900,  894,  875, 1771,  730,\n",
       "          1877, 1429,  178,  178, 1778, 1390,  277, 1188,  952, 1188,  277,\n",
       "           178, 1119, 1074,  941,  624, 1303,  457, 1132,  484,  952,  178,\n",
       "          1188, 1550,  634, 1989,  378, 1557, 1557, 1104,   35,  443,  506,\n",
       "          1074],\n",
       "         [2048, 2048, 1758, 1469, 1671, 1583,  654, 1394,  826, 1889, 1113,\n",
       "           902,  334, 1143,  789, 1583, 1336,  235, 1482, 1394, 1955, 1137,\n",
       "          1583, 1275, 1941, 1102, 1793, 1583, 1085, 1394, 1931, 1793, 2044,\n",
       "           154, 2044, 2044, 1497, 2044, 1931, 1881, 1931, 1938, 1394, 1583,\n",
       "          1330, 1497, 1931, 2044, 1726, 1810,  553, 1684, 1857, 1330, 1976,\n",
       "          1361, 1435,  853, 2035, 1166, 2035,  256,  706,  607, 1370, 1166,\n",
       "             0,  149,  794, 1415, 1671,  953, 1514, 1464,  554, 1224,  861,\n",
       "          1640, 1432, 1477, 1420, 1155,  858,  838, 1051, 1475, 1762,  901,\n",
       "          1599, 1673, 1599,  144, 1751,  533, 1004, 1737,  977, 1175, 1882,\n",
       "           879],\n",
       "         [2048, 2048, 2048, 1725, 1725, 1364, 1423, 2004, 1947, 2019, 1919,\n",
       "          1912,  391, 1729, 1172, 1941, 1689, 1007,  732, 1492, 1954, 1439,\n",
       "           471, 1931,  991, 1423, 1808, 1914, 1895, 1836, 1074, 1949, 2019,\n",
       "          2019, 2019, 2019, 2019, 2019, 2019, 1708, 1423, 1895,  969, 1919,\n",
       "           991, 1919, 1725, 1895, 1947,  547, 1504, 1945, 1717, 1982, 1748,\n",
       "          1385,  207, 1659, 1107,  176,  262, 1343, 1331, 1115,  262,  911,\n",
       "          1598,  386, 1963,  551, 1616, 1702, 1474, 1474, 1352, 1992, 1177,\n",
       "          2014, 1294, 1204,  878, 1212,  631, 1721, 1523,  443,  164, 1204,\n",
       "          1952,  393, 2040, 1131, 1377, 2038, 1967, 1967, 1022, 1910,   49,\n",
       "          2040],\n",
       "         [2048, 2048, 2048, 2048, 1467,   56,   11, 2040, 1145, 1015, 2036,\n",
       "          1215,  893, 1631,  602,  933,  558, 1684, 1891, 1927, 1259, 1910,\n",
       "            26,  685,  705,  685, 1946,  380, 1537, 1215,  685, 1145, 2040,\n",
       "          1994,  358, 1854, 1770, 1854, 1854, 1854, 1380,  498,  651, 1145,\n",
       "          1394, 2040, 1770,  822, 1854, 1910,   50, 1380,  723, 1946,  827,\n",
       "           706,  638, 1782,  314, 1303, 1741,  777,  564, 1518, 1855, 1506,\n",
       "           209,   89, 1887,  551,  682, 1208,  682,  353, 1123,  671, 1615,\n",
       "           630, 1357, 1210,  823, 1962, 1848, 1499,  313,  933,   94, 1435,\n",
       "          1150, 1521, 1130,  170,  646,   26,  879,   64,  510, 1219, 1098,\n",
       "          1598]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:, :, :100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df674630-9c01-43c4-b4d9-40b3c61f95cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
